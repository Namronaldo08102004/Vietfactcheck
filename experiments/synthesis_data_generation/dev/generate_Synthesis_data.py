import os
import json
import time
import sys
from typing import List
from pathlib import Path
from tqdm import tqdm

from dotenv import load_dotenv
from google import genai

# ------------------------------------------------------------------
# Path handling
# ------------------------------------------------------------------
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, "../../../"))
sys.path.append(PROJECT_ROOT)
sys.path.append(os.path.join(PROJECT_ROOT, "src"))

# ======================================================================
# CONFIGURATION
# ======================================================================

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    raise RuntimeError("GOOGLE_API_KEY is not set")

MODEL_NAME = "models/gemini-2.5-pro" # ÄÃ£ cáº­p nháº­t model name má»›i nháº¥t
client = genai.Client(api_key=GOOGLE_API_KEY)

CONTEXT_GENERATION_PROMPT = """
Báº¡n lÃ  chuyÃªn gia táº¡o ngá»¯ cáº£nh cho dá»¯ liá»‡u kiá»ƒm tra sá»± tháº­t.
Chá»§ Ä‘á»: {topic}
Cho cÃ¡c CÃ‚U TUYÃŠN Bá»:
{statements}

HÃ£y táº¡o ra Má»˜T Ä‘oáº¡n CONTEXT GIáº¢ sao cho:
- PhÃ¹ há»£p vá»›i chá»§ Ä‘á»
- Logic, tá»± nhiÃªn nhÆ° bÃ i bÃ¡o
- Sao chÃ©p nguyÃªn vÄƒn statements nhÆ°ng bá»• sung thÃªm cÃ¡c tá»« ná»‘i Ä‘á»ƒ cÃ¢u vÄƒn trÃ´i cháº£y, máº¡ch láº¡c

CHá»ˆ TRáº¢ Vá»€ Má»˜T CHUá»–I VÄ‚N Báº¢N (string).
KHÃ”NG JSON, KHÃ”NG markdown, KHÃ”NG giáº£i thÃ­ch.
"""

# ======================================================================
# UTILITY FUNCTIONS
# ======================================================================

def generate_fake_context(topic: str, statements: List[str]) -> str:
    """HÃ m gá»i API Gemini Ä‘á»ƒ sinh text"""
    prompt = CONTEXT_GENERATION_PROMPT.format(
        topic=topic,
        statements="\n".join(f"- {s}" for s in statements)
    )

    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt,
    )
    
    if not response.text:
        raise RuntimeError("Gemini returned an empty response")
        
    return response.text.strip()

def process_grouped_full_context(
    input_path: str,
    output_path: str,
    max_items: int | None = None,
    max_retries: int = 5,
    time_sleep_retry: int = 15
):
    in_path = Path(input_path)
    out_path = Path(output_path)
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # 1. Load data
    with in_path.open("r", encoding="utf-8") as f:
        data = json.load(f)
    
    if max_items:
        data = data[:max_items]
    
    total = len(data)
    results = []

    # 2. Resume Logic: Náº¿u file output Ä‘Ã£ tá»“n táº¡i, load dá»¯ liá»‡u cÅ©
    if out_path.exists() and out_path.stat().st_size > 0:
        try:
            with out_path.open("r", encoding="utf-8") as f:
                existing_data = json.load(f)
                # Táº¡o map Ä‘á»ƒ check nhanh dá»±a trÃªn topic/statements (hoáº·c ID náº¿u cÃ³)
                results = existing_data
                print(f"[+] Resuming: Found {len(results)} existing records.")
        except Exception as e:
            print(f"[!] Could not resume: {e}")

    def save_progress(data_to_save):
        with out_path.open("w", encoding="utf-8") as f:
            json.dump(data_to_save, f, ensure_ascii=False, indent=2)

    # 3. Processing loop
    try:
        with tqdm(total=total, unit="rec", desc="Generating Context") as pbar:
            # Náº¿u resume, skip pbar tá»›i vá»‹ trÃ­ hiá»‡n táº¡i
            pbar.update(len(results))

            for idx in range(len(results), total):
                item = data[idx]
                statements_text = [s["text"] for s in item["statements"]]
                
                success = False
                attempts = 0

                while not success and attempts < max_retries:
                    try:
                        fake_context = generate_fake_context(
                            topic=item["topic"],
                            statements=statements_text
                        )
                        
                        # ThÃªm káº¿t quáº£ má»›i vÃ o list
                        results.append({
                            "topic": item["topic"],
                            "Context": fake_context,
                            "Statement_list": statements_text,
                        })
                        
                        # LÆ°u ngay láº­p tá»©c (Checkpoint)
                        save_progress(results)
                        success = True
                        pbar.update(1)

                    except Exception as e:
                        attempts += 1
                        err_msg = str(e)
                        
                        # Kiá»ƒm tra lá»—i Rate Limit hoáº·c Server
                        if any(code in err_msg for code in ("429", "ResourceExhausted", "503", "500")):
                            print(f"\n[!] Rate limit/Server error (Attempt {attempts}/{max_retries}). Sleeping {time_sleep_retry}s...")
                            time.sleep(time_sleep_retry)
                        else:
                            print(f"\n[!] Unrecoverable error at index {idx}: {e}")
                            save_progress(results) # LÆ°u nhá»¯ng gÃ¬ Ä‘Ã£ lÃ m Ä‘Æ°á»£c
                            raise e # Dá»«ng chÆ°Æ¡ng trÃ¬nh náº¿u lÃ  lá»—i logic/auth

            print(f"\nðŸŽ‰ Done: Processed {len(results)} samples")

    except KeyboardInterrupt:
        print("\n[!] Process interrupted by user. Saving progress...")
        save_progress(results)
        sys.exit(0)
    except Exception as e:
        print(f"\n[!] Critical error: {e}")
        save_progress(results)
        raise

# ======================================================================
# ENTRY POINT
# ======================================================================

if __name__ == "__main__":
    input_file = os.path.join(
        PROJECT_ROOT,
        "experiments/synthesis_data_generation/dev/results/dev_parse_data/dev_grouped_full_context.json"
    )

    output_file = os.path.join(
        PROJECT_ROOT,
        "experiments/synthesis_data_generation/dev/results/dev_synthesis_data/dev_fake_context.json"
    )

    process_grouped_full_context(
        input_path=input_file,
        output_path=output_file,
        max_items=150, 
        max_retries=10,
        time_sleep_retry=10
    )